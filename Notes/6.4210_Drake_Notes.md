# 6.4210 Notes

# Drake
[[source]](https://deepnote.com/workspace/michael-zengs-workspace-61364779-69ef-470a-9f8e-02bf2b4f369c/project/Tutorials-Duplicate-9e3ac27c-cff2-4df4-b6f4-6c867be9f48b/notebook/dynamical_systems-28a9f57bd802463689944ad6a8e289c2)

## SymbolicVectorSystem
Basic input, state, output systems. Either continuous time or discreet time.

- `x` = state vector
- `u` = input vector
- `y` = output vector

For example (continuous):
$$
\dot{x} = -x + x^3
\\
y = x
$$

Translated into Drake:
```python
from pydrake.symbolic import Variable
from pydrake.systems.primitives import SymbolicVectorSystem

# Define a new symbolic Variable
x = Variable("x")

# Define the System.  
continuous_vector_system = SymbolicVectorSystem(state=[x], dynamics=[-x + x**3], output=[x])
```
<br />

## LeafSystem
While `SymbolicVectorSystem` is simple, SISO, either continuous or discreet time, deriving from `LeafSystem` directly --> all those limitations go away.

Same example as above:
```python
from pydrake.systems.framework import LeafSystem

# Define the system.
class SimpleContinuousTimeSystem(LeafSystem):
    def __init__(self):
        LeafSystem.__init__(self)

        state_index = self.DeclareContinuousState(1)  # One state variable.
        self.DeclareStateOutputPort("y", state_index)  # One output: y=x.

    # xdot(t) = -x(t) + x^3(t)
    def DoCalcTimeDerivatives(self, context, derivatives):
        x = context.get_continuous_state_vector().GetAtIndex(0)
        xdot = -x + x**3
        derivatives.get_mutable_vector().SetAtIndex(0, xdot)

# Instantiate the System
continuous_system = SimpleContinuousTimeSystem()
```
<br />


## Simulation

**Robot Description Files (containing information to model the arm)**: URDF, SDF

Pass diagram (returned by `DiagramBuilder.build()`) or `HardwareStation` into Simulator to create a simulator. 

Optionally, pass context into simulator, or else simulator will use its own context.

Use `AdvanceTo` to move time forward.

```python
import matplotlib.pyplot as plt
from pydrake.systems.analysis import Simulator
from pydrake.systems.framework import DiagramBuilder
from pydrake.systems.primitives import LogVectorOutput

# Create a simple block diagram containing our system.
builder = DiagramBuilder()
system = builder.AddSystem(continuous_vector_system)  # Add a system to simulate
logger = LogVectorOutput(system.get_output_port(0), builder)
diagram = builder.Build()

# Set the initial conditions, x(0).
context = diagram.CreateDefaultContext()
context.SetContinuousState([0.9])

# Create the simulator, and simulate for 10 seconds.
simulator = Simulator(diagram, context)
simulator.AdvanceTo(10)

# Plot the results.
log = logger.FindLog(context)
plt.figure()
plt.plot(log.sample_times(), log.data().transpose())
plt.xlabel('t')
plt.ylabel('y(t)')
```

### Context
Contains critical info of a system for simulation (i.e. time, state, system inputs, system parameters). Basically, is a system-wide struct that is accessible to all system functions.

All of a context's input ports must be connected to either the output of another system or set to a fixed value.

```python
context = simulator.get_mutable_context()
```

### Diagram & DiagramBuilder
Combine systems into more complex systems. `DagramBuilder` class has `AddSystem()`, `Connect()` (to connect input ports to output ports). `Build()` generates new `Diagram` instance.

Example with 3 systems: plant (which is a pendulum), controller, logger.
```python
import matplotlib.pyplot as plt
import numpy as np
import pydot
from IPython.display import SVG, display
from pydrake.examples import PendulumPlant
from pydrake.systems.analysis import Simulator
from pydrake.systems.controllers import PidController
from pydrake.systems.framework import DiagramBuilder
from pydrake.systems.primitives import LogVectorOutput

builder = DiagramBuilder()

# First add the pendulum.
pendulum = builder.AddNamedSystem("pendulum", PendulumPlant())

# Add a PID controller.
controller = builder.AddNamedSystem("controller",
                                    PidController(kp=[10.], ki=[1.], kd=[1.]))

# Now "wire up" the controller to the plant.
builder.Connect(pendulum.get_state_output_port(),
                controller.get_input_port_estimated_state())
builder.Connect(controller.get_output_port_control(), pendulum.get_input_port())

# Make the desired_state input of the controller an input to the diagram.
builder.ExportInput(controller.get_input_port_desired_state())
# Make the pendulum state an output from the diagram.
builder.ExportOutput(pendulum.get_state_output_port())

# Log the state of the pendulum.
logger = LogVectorOutput(pendulum.get_state_output_port(), builder)
logger.set_name("logger")

diagram = builder.Build()
diagram.set_name("diagram")

# Visualize the diagram.
display(SVG(pydot.graph_from_dot_data(
    diagram.GetGraphvizString(max_depth=2))[0].create_svg()))
```

Example simulation of the pendulum + PID controller system:
```python
# Set up a simulator to run this diagram.
simulator = Simulator(diagram)
context = simulator.get_mutable_context()

# We'll try to regulate the pendulum to a particular angle.
desired_angle = np.pi/2.

# First we extract the subsystem context for the pendulum.
pendulum_context = diagram.GetMutableSubsystemContext(pendulum, context)
# Then we can set the pendulum state, which is (theta, thetadot).
pendulum_context.get_mutable_continuous_state_vector().SetFromVector(
    [desired_angle + 0.1, 0.2])

# The diagram has a single input port (port index 0), which is the desired_state.
diagram.get_input_port(0).FixValue(context, [desired_angle, 0.])

# Simulate for 10 seconds.
simulator.AdvanceTo(10)

# Plot the results.
log = logger.FindLog(simulator.get_context())
t = log.sample_times()
plt.figure()
# Plot theta.
plt.plot(t, log.data()[0,:],'.-')
# Draw a line for the desired angle.
plt.plot([t[0], t[-1]], [desired_angle, desired_angle], 'g' )
plt.xlabel('time (seconds)')
plt.ylabel('theta (rad)')
plt.title('PID Control of the Pendulum')
```



## Inverse Kinematics
A system that can be added to the diagram. Takes coordinates as inputs, and outputs iiwa positions. 

Use DiagramBuilder.Connect() to attach the output of the inverse kinematics to the input of the IK.

```python
controller_plant = station.GetSubsystemByName(
    "iiwa.controller"
).get_multibody_plant_for_control()
differential_ik = AddIiwaDifferentialIK(
    builder,
    controller_plant,
    frame=controller_plant.GetFrameByName("iiwa_link_7"),
)
builder.Connect(
    differential_ik.get_output_port(),
    station.GetInputPort("iiwa.position"),
)
builder.Connect(
    station.GetOutputPort("iiwa.state_estimated"),
    differential_ik.GetInputPort("robot_state"),
)
```


## Hardware Station
Simplified version of creating diagram; takes YAML and handles all the diagram and connections for you. All you need to do is create a simulator.

Has input ports and output ports. i.e. if we create a hardware station with and iiwa and a WSG hand, we get inputs iiwa.position, iiwa.feedforward_torque, wsg.position, wsg.force_limit, and output ports (i.e. iiwa.torque_measured, iiwa.position_measured, wsg.state_measured, etc.).

To access these ports, use `station.GetOutputPort("iiwa.position_measured").Eval(context)` where context is created by `context = station.CreateDefaultContext()`. Or, `station.GetInputPort("iiwa.position").FixValue(context, q_cmd)`.

Simple example that sets iiwa arm joint positions in 2D:
```python
scenario_data = """
directives:
- add_directives:
    file: package://manipulation/clutter.dmd.yaml
model_drivers:
    iiwa: !IiwaDriver
      hand_model_name: wsg
    wsg: !SchunkWsgDriver {}
"""
scenario = load_scenario(data=scenario_data)
station = MakeHardwareStation(scenario, meshcat=meshcat)

simulator = Simulator(station)

context = simulator.get_mutable_context()

simulator.set_target_realtime_rate(1.0 if interactive else 0)
meshcat.AddButton("Stop Simulation")

while meshcat.GetButtonClicks("Stop Simulation") < 1:
    simulator.AdvanceTo(simulator.get_context().get_time() + 2.0)

    # Print current joint positions
    q_current = station.GetOutputPort("iiwa.position_measured").Eval(context)
        print(f"Current joint angles: {q_current}")

    # Set new joint postions to whatever q_cmd is
    station.GetInputPort("iiwa.position").FixValue(context, q_cmd)

    # Should print values equal to q_cmd
    print(station.GetOutputPort("iiwa.position_commanded").Eval(context))

meshcat.DeleteButton("Stop Simulation")
```

## Optimization Solver

### About Quadratic Programming (the math)

Defined as a quadratic objective function w/Linear constraints.

Typically in the form:

$$ \min\limits_{x} \frac{1}{2} x^T A x + b^t x$$

Constraints can be in the following forms:
- Bounding Box: $LB \leq x \leq UB$
- Equality Constraint: $Cx = d$

If you plot the objective, is a paraboloid, convex, analytically solvable.


```python
prog = MathematicalProgram()
x = prog.NewContinuousVariables(2)
prog.AddConstraint(x[0] + x[1] == 1)
prog.AddCost(x[0]**2 + x[1]**2)
result = Solve(prog)

# print out the result.
print("Success? ", result.is_success())
# Print the solution to the decision variables.
print('x* = ', result.GetSolution(x))
```

Common Cost: If cost is a product of matrices, `a.dot(b)` multiplies $a^Tb$: 
```python
# These are equivalent:
prog.AddCost(x.dot(x))
prog.AddCost(x[0]**2 + x[1]**2)
```

Common Equality Constraints:
```python
prog.AddConstraint(le(x, 2*np.ones))  # all components of x must be <= 2
prog.AddConstraint(ge(x, 4*np.ones))  # all components of x must be >= 4
prog.AddConstraint(eq(x, 0.5*np.ones))  # all components of x must equal to 0.5
```

"Bounding Box" Constraint:
```python
# x (a 3x1 vector) must be >= [-0.35, -0.35, -0.35] and <= [0.35, 0.35, 0.35]
prog.AddBoundingBoxConstraint(-0.35*np.ones(3), 0.35*np.ones(3), x)
```

Note: to add constraints on position or rotation of a pose, use `RigidTransform.translation()` and `RigidTransform.rotation()`

Drake has examples of quadratic program, etc.

Examples: https://deepnote.com/workspace/Manipulation-ac8201a1-470a-4c77-afd0-2cc45bc229ff/project/03-Basic-Pick-and-Place-65aad364-ef1c-45f5-a796-fac7c122e274/notebook/09_intro_to_qp-79dfbe9d7a0e4a9e9ae7576ebdc44aaf

**Best practices for formulating optimization problems:**
- Simple cost function, add as many constraints as needed
- Complex cost functions leads to cost function parameter tuning --> a never-ending mess
- Usually costs are more intuitive as constraints; i.e. non-collision should not incur a cost, it should be a constraint
- Use minimal constraints --> larger set of feasible configurations. Only add constraints that are necessary.

Internally, Drake uses many other libraries to do the optimization, i.e. Gurobi, SNOPT, IPOPT, SCS, MOSEK.


## Multi-body Plant and Plants
Another alternative to HardwareStation & Diagrams.

Simulates a plant that is being controlled, specifically with multiple bodies. Takes torque input, outputs estimated state.

```python
plant = MultibodyPlant(time_step=1e-4)
Parser(plant).AddModelFromFile(".../iiwa14_no_collision.sdf")
plant.WeldFrames(plant.world_frame(), plant.GetFrameByName("iiwa_link_0"))  # Stop iiwa from falling into the ground
plant.Finalize()
```

## Robotics Programming Paradigms

1. Procedural Code (i.e. typical step-by-step script) running in separate thread/process that passes messages to a module/process that runs at high/constant frequency in the main robot thread to control hardware
2. Task Policies - typically FSMs (or "behavior trees") that get evaluated in the robot loop (decides what discrete state it is in every look)
   - enum of states
   - update function that looks at current state + sensors --> decides what state to enter next
   - if statements for each state that determine what to do
   - Pro: can be very robust if all possible states + transitions are captured
   - Con: takes intense testing + full-stack simulation to find all the edge cases/catch all the states.
   - Con: Not good for long-term/complex reasoning; good for short test goal (i.e. open a door, or put simple manipulation)
3. Task Planners chain together task-level behaviors (i.e. open dish washr door, put plate in dish washer) for long-term behavior
   - graph search
   - dynamic/online replanning
   - Using LLMs (if you give it context, current state, list of possible actions, tell it exactly how to produce the output), it will produce list of actions

