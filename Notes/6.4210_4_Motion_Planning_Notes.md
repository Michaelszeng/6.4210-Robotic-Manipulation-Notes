# Motion/Trajectory Planing

## Inverse Kinematics (IK)

Why this is different from Differential IK (in the Dyamics Notes): Diff IK takes partial derivates of joint positions to produce Jacobian, and solve for joint velocities that result in end effector velocities. IK is simply solving for joint angles that produce end effector pose. 

For trajectory planning, IK is typically used.

One way to solve the IK problem is just like this: 

$$ q = f_{kin}^{-1}(X^G) $$

where $f_{kin}$ is the forward-kinematic function that maps $q$ to $X^G$ (like so: $X^G = f_{kin}(q)$).

However, they break down once we have inequality constraints, and are less flexible in terms of customizing costs , contraints, and picking a solution when there are many.

A better, more explicit method is to use optimization:

$$ \min\limits_{q} |q - q_0|^2 $$
$$ subject \space to \space \space \space X^G = f_{kin}(q) $$

Basically, we set some $q_0$ that is a generic "comfortable" position, and an extremely simple cost function that prefers joint positions near the "comfortable position". We then add all our other requirements (i.e. end effector position, non-collision) as constraints.

Implementation in Drake:

<center><img src="solve_ik.png" alt="IK Drake Code" /></center><br />

We're setting pose.translation() as both the lower and upper bound for the position constraint, and th desired rotation as the rotation constraint. We use $|q - q_0|^2$ as the cost.

Optimization gives us the chance to use tons of different constraints (i.e. relative position/orientation of 2 bodies, min. distance between 2 bodies)

Another example of constraints, that require the gripper to be in a "grabbing" position of a cylindrical rod:

```Python
ik.AddPositionConstraint(
    frameB=gripper_frame, p_BQ=[0, 0.1, -0.02],
    frameA=cylinder_frame, p_AQ_lower=[0, 0, -0.5], p_AQ_upper=[0, 0, 0.5])
ik.AddPositionConstraint(
    frameB=gripper_frame, p_BQ=[0, 0.1, 0.02], 
    frameA=cylinder_frame, p_AQ_lower=[0, 0, -0.5], p_AQ_upper=[0, 0, 0.5])
```
<center><img src="grasp_cylinder_1.png" alt="Grab my rod" style="width:20%" /></center><br />

[0, 0.1, 0] is the point in gripper frame in the middle between the 2 fingers. [0, 0.1, 0.02] and [0, 0.1, -0.02] are points equidistant from the 2 fingers, but shifted "left"/"right". We're saying that these 2 points in gripper frame must coincide with the center of the cylinder, +/- 0.5 meters in the z-axis (the length of the cylinder).

A simple constraint in Drake for total non-collision:
```Python
ik.AddMinimumDistanceConstraint(threshold)
```

Can also add filters so the collision constraint only applies to certain objects. Behind the scenes, checks minimum distance between all objects in the scene.


Examples of some IK solvers in Drake: https://deepnote.com/workspace/michael-zengs-workspace-61364779-69ef-470a-9f8e-02bf2b4f369c/project/06-Motion-Planning-Duplicate-c2fb7d28-4b8e-4834-ba5a-a1d69c1d218b/notebook/interactive_ik-64af78e8866a4750932bdb25344edef0?


This provides a visual of an optimization:

This optimization has a 2D decision variable (X and Y axes), and the Z-axis 

https://manipulation.csail.mit.edu/data/shelf_ik_prog.html

The green is the cost, and each constraint (which can be turned on/off in the controls) is either red or blue; red --> infeasible region, blue --> feasible region. Non-linear optimizers need to solve this problem to find the lowest green point where all constraints are blue.

## TODO: IMPROVE EXPLANATION

### Offline vs Online Optimization Solvers

We have a problem: non-linear optimization is a hard problem; online solvers like SNOPT are good and fast, but have no guarantees; i.e. may not find global min. solution, or may not find a solution at all even if there is one. Global solvers are too slow to be real time, but good for applications like creating training data for a RL model (to replace the optimizer), or for two-stage optmizers (with an offlne "building" phase and online "query" phase).

Drake also have `GlobalInverseKinematics` to help solve for global minimums.

## Grasp Planning using IK

Previously (in Bin Picking Notes), we chose a grasp by sampling & evaluating an objective that rewarded grasping from above the object.

A slightly better approach, which we'll describe briefly here, is to use optimization, and optimize considering both picking and placing with two decision variables: $q_{pick}$ and $q_{place}$. We'll constrain $^OX^{G_{pick}} = ^OX^{G_{place}}$, which means that the gripper position relative to the object is constant (obj doesn't move in gripper). (Everything beyond this point is a guess). Our cost function for this optimization can be the same as above, $|q_{pick} - q_0|^2 + |q_{place} - q_0|^2$ (which prefers positions closer to the "comfortable" position), and with the additional constriants that $q_{pick}$ should produce an antipodal grasp, $q_{place}$ should place the object where we want it.

## Trajectory Optimization

To solve the entire trajectory, instead of performing an optimization for every $q$ in the trajectory, we optimize the whole trajectory at once:

$$ \min \limits_{q_0, ... ,q_N} \sum_{n=0}^{N-1} | q_{n+1}-q_n | ^2  $$
$$ subject \space to \space \space \space q_0 = q_{start},$$
$$ \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space q_N = q_{end},$$
$$ \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space  \forall n, \space non-collision $$

Here, we're minimizing the sum of squared distances between adjacent points in the path, in order to spread the distance evenly. This is a very basic path that consists of just line segments. Note that the non-collision constraint is dangerous; we only check non-collision at the $n$ sampled points, not over the entire trajectory.

Another more practical optimization for the trajectory (with the cost being time taken):

$$ \min \limits_{\alpha, T} T $$

$$ subject \space to \space \space \space X^{G_{start}} = f_{kin}(q_{\alpha}(0)),$$
$$ \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space X^{G_{goal}} = f_{kin}(q_{\alpha}(T)),$$
$$ \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space \space  \forall t, \space |\dot{q}_{\alpha}(t)| \leq v_{max} $$

Basically, we find a trajectory, $q_{\alpha}(t)$ for all $t \in [0, T]$ that the gripper moves from start to goal in minimum time. The last equation represents velocity limits for each joint. We can also add constraints that ensure the start/end velocity are 0, and non-collision constraints for all $t$. Also, we can add a multiplier to the cost equal to $|q_{\alpha} - q_0|^2$ to prefer "comfortable" positions.

$\alpha$ here are parameters that define the trajectory; specfically, $\alpha$ are the control points of a B-spline trajectory (similar to the control points of a bezier curves). Why a B-spline?
- Derivatives of B-splines are still B-splines (with degree reduced by one), with coefficients that are linear in the original coefficients.
- The coefficients of the B-spline, called the "control points", have a strong geometric interpretation.
- The B-spline is guaranteed to be within the area bounded by the control points (aka, within the "Convex Hull" of the control points). This is especially nice because we can add a constraint that all control points are within the joint limits, which guarantees that the trajectory is entirely within joint limits.

Joint limits and velocity limits get encoded as linear constraints. However, acceleration, jerk, etc. are non-linear.

We can solve the optimization now to get a B-spline trajectory output.

With non-linear constraints, the optimizer can get stuck in local minima. Sometimes, it's a good idea to run the optimizer multiple times with different initial guesses (i.e. run it once without anti-collision constraints, then run it a second time with anti-collision).

## Sampling-Based Trajectory Planning

Due to limitations of optimization-based trajectory planning (i.e. local minima), sampling-based algorithms have become more popular (i.e. RRT*, PRM).

#### An Aside: PRM (Probabilistic Roadmap)

**Build Phase (can be done offline):**
1. Randomly samples positions ("vertices") in 7D "configuration space" (for a 7D robot); determines which are safe vs in-collision (with obstacle). Note that configuration space is the space where each dimension spans from $0$ to $2 \pi$ and wraps around to 0; it doesn't look at all like 3D physical space.
2. Randomy creates edges between safe vertices that are less than $radius$ distance apart (and check that the edge is safe as well)

**Query Phase (must be done online):**

3. Finds shortest path from start vertex to targer vertex following these edges (i.e. using A*)

If obstacles move, you can reuse vertices, but must recompute them all to see if they are now in-collision, and based on this, create new edges.

Note: PRM paths are not smooth by default; we usually apply a smoothing algorithm after.

This basically converts searching for a path to a graph-search problem, which is easily solvable.

### Graphs of Convex Sets (GCS)

Modification to PRM: every time we add a vertex, instead of addng just a vertex, expand the vertex into a convex region in configuration space. This is done during the building phase, offline. Because we have these convex regions, we also don't need as many vertices. With these convex regions, instead of simply using A* to find the shortest path for the arm, we can optimize within the convex regions to find a continuous curve.


## Time-Optimal Path Parameterizations

